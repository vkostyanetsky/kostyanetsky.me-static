<rss version="2.0">
    <channel>    
        <title>Vlad Kostyanetsky</title>
        <description>Hello! My name is Vlad, I'm business app developer.</description>
        <language>en</language>
        <link>https://kostyanetsky.me</link>
        <lastBuildDate>Sat, 06 Dec 2025 20:57:48 +0700</lastBuildDate>
        
        <item>
            <title>Backup Management</title>
            <link>https://kostyanetsky.me/notes/backup-ui</link>
            <guid isPermaLink="false">note-backup-ui</guid>
            <pubDate>Sat, 06 Dec 2025 20:57:48 +0700</pubDate>
            <description><p>At the end of the year we shipped a big update to our internal tool (I briefly <a href="https://kostyanetsky.me/notes/easter-eggs" target="_blank">wrote</a> about it before). The goal: give teammates sane, usable access to backups of customer apps. In a SaaS company, everyone needs backups all the time — dev, QA, incident investigations, you name it. Without proper tracking the whole thing turns into a petting zoo: three people, same moment, three requests for almost identical copies of the same database. Sure, it "works", but you end up chewing through 3x the resources for zero extra value.</p>
<p>We did have a solution built on top of the Bitrix UI, but due to, uh... the unique "evolutionary path" of that product, it delivered more pain than gain. So we rethought the workflow and rewrote everything. Frontend is 1C; backend is PostgREST, PostgreSQL, PowerShell, and a bunch of other bits and bobs. The internal logic is fairly gnarly, but for the user it's a clean, friendly UI where you can request a backup in literally two clicks.</p>
<p>You can pick one of three backup types:</p>
<ul>
<li>Cloud backup (a copy of the real app deployed in the cloud and accessible — including via the browser);</li>
<li>File backup (a regular .dt file you can download and spin up locally);</li>
<li>Configuration + extensions backup (.cf + .cfe).</li>
</ul>
<p>Also, the new solution detects when someone tries to request a backup for an app that's already being generated right now. And it rate-limits things too: you can't back up the same app more than once per hour.</p>
<p>And yes — we're still sneaking jokes into the UI. Obviously.</p>
<p><img alt="But Still!" src="https://kostyanetsky.me/notes/backup-ui/but-still.png"/></p>
<p><img alt="Coffee First!" src="https://kostyanetsky.me/notes/backup-ui/coffee-first.png"/></p></description>
        </item>
        
        <item>
            <title>Desire Paths</title>
            <link>https://kostyanetsky.me/notes/desire-paths</link>
            <guid isPermaLink="false">note-desire-paths</guid>
            <pubDate>Sat, 29 Nov 2025 21:00:48 +0700</pubDate>
            <description><p>Alright, Jean Fresco's riddle. You've got a table — say, ~50k rows. How do you end up reading half a billion?</p>
<p>Easy-peasy: Nested Loops + Clustered Index Seek:</p>
<p><img alt="Half a billion" src="https://kostyanetsky.me/notes/desire-paths/500_million.png"/></p>
<p>Clustered Index Seek is a bit of a marketing name here, of course. In reality, on every execution the operator walks the entire table (the whole clustered index) and checks every row against the predicates. And it does that 10 730 times for 51 391 rows. Result: 551 425 430 rows read, 13 343 returned.</p>
<p><img alt="Ouch" src="https://kostyanetsky.me/notes/desire-paths/ouch.gif"/></p>
<p>So yeah — a perfect textbook example of a horrible query plan in a vacuum. Put it in a museum. Nested Loops, if you've forgotten, works roughly like this:</p>
<pre>
For Each Table1Row In Table1 Do
    For Each Table2Row In Table2 Do
        ...
</pre>
<p>That's fine for small tables, but the DB can also pick it for bigger ones — for example, if it runs out of time to build a proper plan.</p>
<p>That's exactly what happened here. Zooming out to the platform level: we've got a dynamic list that queries a documents table, and the devs bolted on like a dozen virtual tables from accumulation registers.</p>
<p>Some of those registers were huge on their own, and the virtual tables poured gasoline on the fire (each one turns into 2+ nested queries). The DB honestly tried to come up with an efficient strategy, but at some point it basically decided: "a garbage plan is still better than no plan at all".</p>
<p>And the user? They tried to search a document by number — and the client app just straight-up froze.</p>
<p>So, about virtual tables in dynamic lists. There's a nice English phrase: "desire path" — the trail people naturally carve because it's the easiest way. Slapping a virtual table onto the main one really is often the simplest, fastest, most familiar way to solve the task. But it's <strong>not efficient</strong>.</p>
<p>There's an alternative, for example the <code>OnGetDataAtServer()</code> handler. It takes longer to implement, but it lets you properly tune the virtual table and avoid the scenario above. Scrolling the list will produce more queries, sure — but they'll be smaller, faster, and way more efficient than one single giant monster query.</p></description>
        </item>
        
        <item>
            <title>Food Diary In Obsidian Bases</title>
            <link>https://kostyanetsky.me/notes/obsidian-foodiary-bases</link>
            <guid isPermaLink="false">note-obsidian-foodiary-bases</guid>
            <pubDate>Sun, 23 Nov 2025 00:01:58 +0700</pubDate>
            <description><p>I've rebuilt last year’s <a href="https://kostyanetsky.me/notes/obsidian-foodiary" target="_blank">plugin</a> with <a href="https://help.obsidian.md/bases" target="_blank">Obsidian Bases</a> — it now tracks calories, protein, fat, and carbs in your food.</p>
<p>The result is way more flexible and customizable than the plugin version: if you suddenly decide you want to count fiber as well or just shuffle some columns in the report, you don't have to rewrite, rebuild, or release anything. You just tweak it to your heart's content.</p>
<p>And it doesn't look half bad either:</p>
<p><img alt="UI" src="https://kostyanetsky.me/notes/obsidian-foodiary-bases/base.png"/></p>
<p>All the necessary settings and scripts live in the <a href="https://github.com/vkostyanetsky/ObsidianFoodiaryBases" target="_blank">GitHub repo</a>.</p></description>
        </item>
        
        <item>
            <title>Well, There Are Some</title>
            <link>https://kostyanetsky.me/notes/well-there-are-some</link>
            <guid isPermaLink="false">note-well-there-are-some</guid>
            <pubDate>Mon, 17 Nov 2025 13:26:00 +0700</pubDate>
            <description><p>I'm out for a walk in the evening, and behind me there's some mom and her little kid — about five years old, I guess. I don't see them, I just hear them talking. The mom is explaining university to the kid: that you have to get in, study, there will be exams and all that.</p>
<p>The boy is quiet for a bit, then says sadly:</p>
<p>— I thought there was only school, but it turns out there are more difficulties too...</p></description>
        </item>
        
        <item>
            <title>Harmless Harm</title>
            <link>https://kostyanetsky.me/notes/harmless-harm</link>
            <guid isPermaLink="false">note-harmless-harm</guid>
            <pubDate>Sun, 16 Nov 2025 10:36:00 +0700</pubDate>
            <description><p>The other day my colleague and I were debugging an issue, nothing fancy, just another "why is this query behaving weird?" moment.</p>
<p>Simplified, the idea was: we read a table from the database and dump the result into a temp table. If a certain condition is met, we still want the temp table to be created, but it must be empty (regardless of whether the source table has rows or not).</p>
<p>The query looked roughly like this:</p>
<pre>
SELECT
    Table.Field1 AS Field1
FROM
    Table AS Table
WHERE 
    &amp;Parameter
</pre>
<p>If we needed to copy rows from the source table into the temp table, we passed TRUE into the parameter; if we wanted the temp table to be empty, we passed FALSE.</p>
<p>Looks simple at first glance, but this trick is a silent performance foot-gun if the table being read is large.</p>
<p>The reason is how DB engines work with parameterized queries. Both MS SQL and PostgreSQL build the execution plan based on the query text, and in this example the parameter value does <strong>not</strong> affect the decision of whether the table should be read or not.</p>
<p>As a result, when this query runs, both engines will pedantically scan the whole table (or its index), even if the parameter is FALSE. In that case each row is just discarded, so the logic is technically correct, but we're wasting resources on a pointless scan and polluting the buffer cache, slowing down the system overall and diligently contributing to global warming :)</p>
<p>The fix is simple: inline TRUE/FALSE in the query body as a constant instead of using a parameter. Or use TOP so the query text is even simpler:</p>
<pre>
SELECT TOP 0
    Table.Field1 AS Field1
FROM
    Table AS Table
</pre>
<p>At the SQL level this turns into something like "SELECT TOP 0 ... FROM Table" for MS SQL and "SELECT ... FROM Table LIMIT 0" for PostgreSQL. The final plan will still contain a read operator, but the executor won't actually request any rows, so there's no real data scan (yay).</p>
<p>P.S. If you don't care about having proper column types in the temp table, you can even do this:</p>
<pre>
SELECT TOP 0
    UNDEFINED AS Field1
</pre>
<p>The performance gain, however, is so tiny that it's probably not worth over-optimizing for this. There are better hills to die on.</p></description>
        </item>
        
        <item>
            <title>Voodoo</title>
            <link>https://kostyanetsky.me/notes/voodoo</link>
            <guid isPermaLink="false">note-voodoo</guid>
            <pubDate>Sun, 05 Oct 2025 23:54:12 +0700</pubDate>
            <description><p>Looks like we finally caught our first lab-reproducible case of platform cache corruption. Short synopsis:</p>
<ul>
<li>Spin up a fresh app from the v35 template of <a href="https://firstbit.ae" target="_blank">our ERP</a>.</li>
<li>Run it and wait for initialization to finish.</li>
<li>Swap the app configuration to the v36 release (specifically build 28537 from the dev repo) and run it again.</li>
</ul>
<p>After this super simple sequence, about half the team sees the platform suddenly lose one of the enums. And it's annoyingly selective: hit an enum value on the client — all good; do the same on the server — boom, exception.</p>
<p>Same story with the manager module of one catalog: its methods exist and are exported, but after the update the platform pretends they don't and throw an exception when you call them.</p>
<p><a href="https://x.com/EffinBirds/status/1970264357427704080" target="_blank"><img alt="Welcome To Dipshit Central" src="https://kostyanetsky.me/notes/voodoo/welcome.jpg"/></a></p>
<p>As always, when the magic blooms — look at the cache. Clear it and symptoms vanish. There are indirect hints too:</p>
<ul>
<li>The enum did exist in v35, but it was renamed in v36.</li>
<li>Those manager-module methods didn't exist in v35 (they were added in v36).</li>
</ul>
<p>So the v35 cache didn't contain either of these in their v36 identities, yet for some reason the platform insists on digging into that old cache.</p>
<p>We still don't have a clean root cause. We traced it to a specific commit after which the bug started showing up, but the only weird thing there its <a href="https://kostyanetsky.me/notes/voodoo/the-commit.png" target="_blank">its name</a> (and honestly, there are nearby commits that look even <a href="https://kostyanetsky.me/notes/voodoo/the-other-commit.png" target="_blank">more suspicious</a> from this point of view). The rest were <a href="https://kostyanetsky.me/notes/voodoo/5ba6ac0956e0cc7bc6b520e5110420e6950478fe.diff" target="_blank">minor changes</a> that regenerate internal metadata IDs in the manifest. Yes, those IDs are tied to cache keys, but they get bumped on any metadata change and have never caused issues before.</p>
<p>If you landed here from Google because you hit the same mess — make a no-op change to the problematic object so the platform refreshes the metadata IDs in the manifest. For example, add an empty method or even just a space in the module. That fixes the configuration so the recipe at the top stops corrupting the cache.</p>
<p>Voodoo, sure — but hey, it works ¯\_(ツ)_/¯</p></description>
        </item>
        
        <item>
            <title>Slow Removal of Fresh Areas</title>
            <link>https://kostyanetsky.me/notes/data-history-missing-indexes</link>
            <guid isPermaLink="false">note-data-history-missing-indexes</guid>
            <pubDate>Sun, 03 Aug 2025 16:25:35 +0700</pubDate>
            <description><p>A colleague noticed that on one of our Fresh instances, deleting data areas had become painfully slow. Dug into the metrics:</p>
<pre>
DELETE FROM T1
FROM _DataHistoryMetadata T1
WHERE 
    T1._MetadataId = ?
    AND T1._IsActual = 0x00 
    AND NOT (
        T1._MetadataVersionNumber IN (
            SELECT T2._MetadataVersionNumber AS MetadataVersionNumber_
            FROM _DataHistoryVersions T2
            WHERE T2._HistoryDataId IN (
                SELECT DataHistoryLatestVersions1.DataHistoryLatestVersions._HistoryDataId AS HistoryDataId_
                FROM DataHistoryLatestVersions1.DataHistoryLatestVersions T3
                WHERE DataHistoryLatestVersions1.DataHistoryLatestVersions._MetadataId = ?
            )
        )
    )
</pre>
<p>Each of these queries was reading around 20GB. What's happening is mostly clear: the platform is trying to delete an area's data history, but the janky DB query causes a full scan over the whole history table across all areas instead of using an index. Someone on Dmitrovskaya got lazy again.</p>
<p><a href="https://x.com/EffinBirds/status/1945545263407301033" target="_blank"><img alt="Why are you surpised?" src="https://kostyanetsky.me/notes/data-history-missing-indexes/why.png"/></a></p>
<p>So we were losing between 30 seconds and a half an hour per operation. Wanted it faster. Fix:</p>
<pre>
CREATE NONCLUSTERED INDEX IX_DataHistoryLatestVersions1_MetadataId
  ON dbo._DataHistoryLatestVersions1 (_MetadataId)
  INCLUDE (_HistoryDataId)
  WITH (DROP_EXISTING = OFF, ONLINE = OFF);

CREATE NONCLUSTERED INDEX IX_DataHistoryVersions_MetadataVersionNumber
  ON dbo._DataHistoryVersions (_MetadataVersionNumber)
  WITH (DROP_EXISTING = OFF, ONLINE = OFF);
</pre>
<p>Deletion cost predictably dropped ~99%.</p>
<p>If you're going to repeat this on your side:</p>
<ol>
<li>Technically this violates the license agreement, you've been warned and all that.</li>
<li>There's a risk the platform will trip over the new indexes during future restructurings (especially on the "new" schema). Better to have a ready script to drop the index, and then (after restructuring) put it back.</li>
</ol></description>
        </item>
        
        <item>
            <title>Myth Buster</title>
            <link>https://kostyanetsky.me/notes/myth-buster</link>
            <guid isPermaLink="false">note-myth-buster</guid>
            <pubDate>Sun, 27 Jul 2025 12:21:32 +0700</pubDate>
            <description><p>I stumbled upon a hefty Infostart <a href="https://infostart.ru/1c/articles/2434171/" target="_blank">article</a> all about "debunking myths" around the platform.</p>
<p>Honestly, about half of it reads like a joke. It's like:</p>
<blockquote>
<p>Hot off the press! Crime, intrigue, investigations! File‑based infobase is faster than client-server! DCS is slower than a plain request! Calling a server method on the server counts as a brand-new server call! <s>UFO over Red Square!</s></p>
</blockquote>
<p>Still, there are some genuinely interesting nuggets! For instance, I'd never heard the claim that cramming your code into one single line makes it run ten times faster. Too bad you'd get your ass handed to you by the team for trying that kind of desperate swag before you even get to celebrate the speed boost. And let's be real — most enterprise app slowdowns usually come from totally different places.</p>
<p>Or take their speed comparison for dumping data into a table: one test for object presentations and another for their descriptions. The presentation dump was literally tens of times slower! On paper, that sounds weird — both are just strings already pulled from the database at measurement time. My guess is it's down to typing: presentation strings can be unlimited length, unlike descriptions. So you get extra memory allocations, helper structures popping up, and bam — that's where the slowdown creeps in.</p>
<p>P.S. I've jotted down some of these points myself before. Off the top of my head — I remember <a href="https://kostyanetsky.me/notes/is-ref-empty" target="_blank">benchmarking</a> ValueIsFilled() and getting a nasty surprise from the built‑in <a href="https://kostyanetsky.me/notes/method-with-surprise" target="_blank">FindByNumber()</a>.</p></description>
        </item>
        
        <item>
            <title>Geometry Deletion</title>
            <link>https://kostyanetsky.me/notes/delete-geometry</link>
            <guid isPermaLink="false">note-delete-geometry</guid>
            <pubDate>Thu, 12 Jun 2025 10:40:43 +0700</pubDate>
            <description><p>I figured out a cool trick for cutting off parts of an object when it intersects with something else. Like, in this gif, there’s a monkey head model in the center, and as a plane moves through it, the part that intersects just disappears.</p>
<p><img alt="Demo" src="https://kostyanetsky.me/notes/delete-geometry/demo.gif"/></p>
<p><a href="https://github.com/vkostyanetsky/3DPlayground/blob/main/Geometry%20Nodes/DeleteGeometry.blend" target="_blank">The idea</a> is pretty simple: you shrink the geometry of the "cutter" object down to a cube, get its min and max coordinates along each axis, and then for every point on the object you're trimming, you check whether it falls within that range. If it does — boom, it gets deleted.</p>
<p>There are tons of ways you could use this. For example, I used it to automatically trim parts of decorative music staff lines on a wall so they wouldn't go across a doorway.</p>
<p><img alt="Example" src="https://kostyanetsky.me/notes/delete-geometry/case.jpg"/></p>
<p>Sure, you could do it by hand, without geometry nodes, but that would kill flexibility. If the wall size, door size, or the angle of the lines changes — you'd have to redo everything from scratch.</p></description>
        </item>
        
        <item>
            <title>No</title>
            <link>https://kostyanetsky.me/notes/no</link>
            <guid isPermaLink="false">note-no</guid>
            <pubDate>Wed, 11 Jun 2025 19:29:33 +0700</pubDate>
            <description><p><img alt="No" src="https://kostyanetsky.me/notes/no/no.jpg"/></p>
<p>This is the message the current platform throws up when you try to connect to an offline server cluster. I do appreciate minimalism in interfaces, of course, but this is definitely over the top.</p>
<p>What's more, the platform is installed with only a single language pack (English) and even launched with a hard override to "Ven VLen", yet somehow the native birches still manage to sprout up. Maybe the C++ library that fires off the message (DataExchangeTcpClientImpl.cpp) is looking at the OS language (Russian) in my case — hard to say.</p>
<p>Anyway, I can't shake the Bugs Bunny vibes every time I see that dialog box.</p>
<p><img alt="No" src="https://kostyanetsky.me/notes/no/bugs-bunny.png"/></p></description>
        </item>
        
    </channel>
</rss>